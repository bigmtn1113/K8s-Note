# 애플리케이션 배포를 위한 고급 설정

<br>

## Pod의 자원 사용량 제한
자원 활용률은 server cluster에서 자원을 얼마나 효율적으로, 빠짐없이 사용하고 있는지를 의미  
K8s는 computing 자원을 container에 할당하기 위한 여러 기능을 제공

<br>

### Container와 pod의 자원 사용량 제한 - Limit
자원 할당량을 설정하지 않으면 pod의 container가 node의 물리 자원을 모두 사용할 수 있으므로 자원이 모두 고갈되는 상황 발생 가능성 존재  

<br>

#### Pod에 자원 사용량을 명시적으로 설정
`resource-limit-pod.yaml`  
```yaml
apiVersion: v1
kind: pod
metadata:
  name: resource-limit-pod
  lables:
    name: resource-limit-pod
spec:
  containers:
  - name: nginx
    image: nginx:latest
  resources:
    limits:
      memory: "256Mi"
      cpu: "1000m"
```

<br>

#### Worker node의 가용 자원 확인
![image](https://github.com/bigmtn1113/K8s-Note/assets/46125158/ea037ee9-d5a1-4e05-8d52-31a85eb7fe6f)

`kubectl describe node` 명령어의 출력 내용 중에서 'Non-terminated Pods' 항목에서 실행 중인 pods의 자원 할당량 확인 가능  
'Allocated resources' 항목에서는 해당 node에서 실행 중인 pods의 자원 할당량을 모두 더한 값이 표시

<br>

### Container와 pod의 자원 사용량 제한 - Request
적어도 이 만큼의 자원은 container에게 보장돼야 한다는 것을 의미

Node의 총 자원의 크기보다 더 많은 양의 requests 할당 불가  
K8s의 scheduler는 pod의 requests만큼 여유가 있는 node를 선택해 pod를 생성  
즉, pod를 할당할 때 사용되는 자원할당 기준은 limits가 아닌 requests

> **Note**  
> node에 할당된 pod의 limits 값의 합은 node의 물리 자원의 크기 초과 가능

<br>

#### Overcommit
Requests는 K8s에서 자원의 overcommit을 가능하게 만드는 기능

한정된 computing 자원을 효율적으로 사용하기 위한 방법  
사용 가능한 자원보다 더 많은 양을 가상 machine이나 container에게 할당함으로써 전체 자원의 사용률을 높이는 방법

<br>

#### Pod에 자원 사용량을 명시적으로 설정
`resource-limit-with-request-pod.yaml`
```yaml
apiVersion: v1
kind: pod
metadata:
  name: resource-limit-with-request-pod
  lables:
    name: resource-limit-with-request-pod
spec:
  containers:
  - name: nginx
    image: nginx:latest
  resources:
    limits:
      memory: "256Mi"
      cpu: "1000m"
    requests:
      memory: "128Mi"
      cpu: "500m"
```

<br>

### CPU 자원 사용량의 제한 원리
K8s는 CPU를 압축 가능한(compressible) resource라고 지칭  
Requests보다 더 많은 CPU를 사용해 CPU 경합이 발생하더라도 container의 CPU 사용량을 throttle을 통해 억제할 수 있기 때문

Memory나 storage는 압축 불가능(incompressible)한 resource라고 지칭  
Container간에 memory 사용의 경합이 발생하면 우선순위가 낮은 container의 process가 먼저 종료되기 때문

<br>

### QoS class와 memory 자원 사용량 제한 원리
Node에 memory 자원이 부족해지면 어떤 pod나 process가 먼저 종료돼야 하는지는 상당히 중요한 부분  
K8s는 pod의 container에 설정된 limits와 requests의 값에 따라 내부적으로 우선순위를 계산

<br>

#### K8s에서의 memory 부족과 OOM(Out Of Memory)
K8s의 node에는 각종 node의 이상 상태 정보를 의미하는 Conditions라는 값이 존재  
Kubelet은 node의 자원 상태를 주기적으로 확인하면서 Conditions의 MemoryPressure, DiskPressure 등의 값을 갱신

평소에 memory가 부족하지 않을 때는 MemoryPressure의 값이 False로 되어 있으나 memory가 부족해지면 MemoryPressure의 값이 True로 변경

MemoryPressure는 기본적으로 node의 가용 memory가 100Mi 이하일 때 발생하도록 kubelet에 설정된 상태  
MemoryPressure가 발생하면 K8s는 해당 node에서 실행 중이던 모든 pod에 대해 순위를 매긴 후, 가장 우선순위가 낮은 pod를 다른 node로 퇴거(Evict).
그리고 MemoryPressure의 값이 True인 node에는 더 이상 pod를 할당하지 않음

> **Note**  
> **Hard Eviction Threshold**
>
> MemoryPressure와 같이 상태를 감지하기 위한 임계치를 Hard Eviction Threshold라고 지칭  
> kubelet의 실행 옵션에서 설정값 변경 가능  
> Hard Eviction Threshold의 다른 예시로 DiskPressure가 있으며, DiskPressure의 상태가 활성화되면 K8s는 사용 중이지 않은 docker image를 자동으로 삭제

Kubelet이 MemoryPressure 상태를 감지하기 전에 급작스럽게 memory 사용량이 많아질 경우,
linux system의 OOM Killer가 우선순위 점수가 낮은 container의 process를 강제로 종료해 사용 가능한 memory를 확보

OOM Killer는 linux에 기본적으로 내장된 기능이므로 아무것도 설정하지 않아도 모든 process에 자동으로 OOM 점수가 매겨짐  
OOM 점수가 높으면 높을수록 강제로 종료될 가능성이 커지므로 절대로 종료되지 말아야 하는 핵심 process는 일반적으로 매우 낮은 값을 부여받음

process가 memory를 얼마나 더 많이 사용하고 있는지에 따라 process의 최종 OOM 점수(oom_ score)가 갱신되는데,
OOM Killer는 이 점수를 기준으로 최종적으로 종료할 process를 선정

<br>

#### QoS class의 종류 - Guaranteed class
K8s에서는 pod의 limits와 requests 값에 따라서 QoS class를 모든 pods에 대해서 설정

Guaranteed class는 pod의 container에 설정된 limits와 requests의 값이 완전히 동일할 때 부여되는 class  
Requests 없이 limits만 정의하면 requests의 값 또한 limits로 동일하게 설정  
즉, 자원의 overcommit이 허용되지 않으므로 할당받은 자원의 사용을 안정적으로 보장 가능

> **Note**  
> Pod 내의 container가 여러 개 존재한다면 모든 containers의 requests와 limits의 값이 완전히 같아야만 pod가 Guaranteed class로 분류

<br>

#### QoS class의 종류 - BestEffort class
Requests와 limits를 설정하지 않은 pod에 설정되는 class

Limits 값을 설정하지 않았으므로 node에 유휴 자원이 있다면 제한없이 모든 자원 사용 가능  
Requests 또한 설정하지 않아서 보장받을 수 있는 자원이 존재하지 않음

<br>

#### QoS class의 종류 - Burstable class
Requests와 limits가 설정돼 있지만, limits 값이 requests보다 큰 pod를 의미

Requests에 지정된 자원만큼 사용을 보장받을 수 있지만，상황에 따라서는 limits까지 자원 사용 가능  
Requests를 넘어 limits 범위 내에서 자원을 사용하려고 시도한다면 다른 pod와 자원 경합이 발생할 가능성 존재

<br>

#### QoS class와 memory 부족
Pod가 다른 node로 evict되면 단순히 다른 node에서 pod가 다시 생성될 뿐이지만, OOM Killer에 의해 pod container의 process가 종료되면 해당 container는 pod의 restartPolicy에 의해 다시 시작됨

> **Note**  
> OOM Killer는 memory를 많이 사용하고 있는 process를 강제로 종료하는 것이지, container나 pod를 종료시키는 것은 아님  
> Container 내부의 init process가 아닌 다른 process가 memory를 많이 사용하고 있다면 해당 process만 종료될 수 있음

기본적으로 pod의 우선순위는 Guaranteed - Burstable - BestEffort 순  
단, 이는 절대적인 것은 아니며 pod가 memory를 많이 사용할수록 우선순위가 낮아짐

<br>

### ResourceQuota와 LimitRange
특정 namespace에서 pod에 자원을 과도하게 사용해 버리면 다른 namespace에서는 자원이 부족한 상황 발생할 수도 있으니, 각 namespace에서 할당할 수 있는 자원의 최대 한도 또는 범위 설정 필요

<br>

#### ResourceQuota로 자원 사용량 제한
ResourceQuota는 특정 namespace에서 사용할 수 있는 자원 사용량의 합을 제한할 수 있는 K8s object
- Namespace에서 할당 가능한 자원의 총합 제한 가능
- Namespace에서 생성 가능한 resource의 개수 제한 가능

ResourceQuota는 namespace에 종속되는 object이므로 namespace별로 생성

`resource-quota.yaml`
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: resource-quota-example
  namespace: default
spec:
  hard:
    requests.cpu: "1000m"
    requests.memory: "500Mi"
    limits.cpu: "1500m"
    limits.memory: "1000Mi"
```

새롭게 생성되는 pod가 한계치보다 더 많은 자원을 사용하려고 하면 pod를 생성하는 API 요청은 실패  
단, ResourceQuota를 생성하기 이전에 존재하고 있던 pods가 이미 자원을 한계치보다 많이 사용하고 있다 해서 기존의 pod가 종료되진 않음

ResourceQuota는 다음과 같은 K8s object의 개수 제한 가능
- Deployment, Pod, Service, ConfigMap, PVC 등의 개수
- NodePort type의 service 개수, LoadBalancer type의 service 개수
- QoS class 중에서 BestEffort class에 속하는 pod의 개수

`quota-limit-pod-svc.yaml`
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: resource-quota-example
  namespace: default
spec:
  hard:
    requests.cpu: "1000m"
    requests.memory: "500Mi"
    limits.cpu: "1500m"
    limits.memory: "1000Mi"
    count/pods: 3
    count/services: 5
```

Resource의 개수를 제한할 때, 정의되는 K8s object 이름은 count/<object 이름>.<API group 이름>  
```yaml
...
spec:
  hard:
    count/resourcequotas: 3
    count/secrets: 3
    count/configmaps: 5
    count/persistentvolumeclaims: 2
    count/services.nodeports: 3
    count/services.loadbalancers: 1
    count/deployments.apps: 0
```

ResourceQuota를 사용하면 BestEffort class의 pod 개수 제한도 가능
`quota-limit-besteffort.yaml`
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: besteffort-quota
  namespace: default
spec:
  hard:
    count/pods: 1
  scopes:
    - BestEffort
```

scopes는 필수 항목은 아니지만, BestEffort 및 Terminating, NotTerminating, NotBestEffort와 같은 pod의 상태를 값으로 입력 가능

BestEffort class의 pod는 아무런 자원 할당을 설정하지 않은 경우에 해당하므로 hard 항목에서 limit.cpu나 limit.memory와 같은 자원 제한 설정과 연결되어 사용하지 않음.
BestEffort class의 pod 개수를 제한할 때는 count/pods만 유효하게 작동

> **Note**  
> Scopes에서 Terminating은 pod의 종료 시간(activeDeadlineSeconds)이 명시적으로 설정된 경우를 의미하는데 보통 job에서 사용

<br>

#### LimitRange로 자원 사용량 제한
특정 namespace에서 할당되는 자원의 범위 또는 기본값을 지정할 수 있는 K8s object
- Pod의 container에 CPU나 memory 할당량이 설정돼 있지 않은 경우, container에 자동으로 기본 requests 또는 limits 값 설정 가능
- Pod 또는 container의 CPU, memory, PVC storage 크기의 최솟값/최댓값 설정 가능

`limitrange-example.yaml`
```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: mem-limit-range
spec:
  limits:
  - default:
      memory: 256Mi
      cpu: 200m
    defaultRequest:
      memory: 128Mi
      cpu: 100m
    max:
      memory: 1Gi
      cpu: 1000m
    min:
      memory: 16Mi
      cpu: 50m
    type: Container
```

- default: pod의 container에 limits 값이 설정돼 있지 않다면 자동으로 이 값을 limits로 설정
- defaultRequest: pod의 container에 requests 값이 설정돼 있지 않다면 자동으로 이 값을 requests로 설정
- max: pod의 container에 설정될 수 있는 limits 값의 최대치
- min: pod의 container에 설정될 수 있는 requests 값의 최소치
- type: 이러한 자원 할당에 대한 설정이 어떤 단위로 적용될 것인지 명시. container, pod, PVC 입력 가능

LimitRange에서 maxLimitRequestRatio 항목을 사용하면 pod의 container에서 overcommit되는 자원에 대한 비율 제한 가능

`limitrange-ratio.yaml`
```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: limitrange-ratio
spec:
  limits:
  - maxLimitRequestRatio:
      memory: 1.5
      cpu: 1
    type: Container
```

Memory 기준으로 limits 값 / requests 값이 1.5가 넘는 pod의 container를 생성하려고 하면 오류 발생  
maxLimitRequestRatio는 overcommit을 얼마나 허용할 수 있는지 제어할 수 있을 뿐만 아니라, 이 값을 1로 설정함으로써 Guaranteed class의 pod만을 생성하도록 강제하는 용도로도 사용 가능


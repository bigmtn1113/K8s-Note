# 애플리케이션 배포를 위한 고급 설정

<br>

## Pod의 자원 사용량 제한
자원 활용률은 server cluster에서 자원을 얼마나 효율적으로, 빠짐없이 사용하고 있는지를 의미  
K8s는 computing 자원을 container에 할당하기 위한 여러 기능을 제공

<br>

### Container와 pod의 자원 사용량 제한 - Limit
자원 할당량을 설정하지 않으면 pod의 container가 node의 물리 자원을 모두 사용할 수 있으므로 자원이 모두 고갈되는 상황 발생 가능성 존재  

<br>

#### Pod에 자원 사용량을 명시적으로 설정
`resource-limit-pod.yaml`  
```yaml
apiVersion: v1
kind: pod
metadata:
  name: resource-limit-pod
  lables:
    name: resource-limit-pod
spec:
  containers:
  - name: nginx
    image: nginx:latest
  resources:
    limits:
      memory: "256Mi"
      cpu: "1000m"
```

<br>

#### Worker node의 가용 자원 확인
![image](https://github.com/bigmtn1113/K8s-Note/assets/46125158/ea037ee9-d5a1-4e05-8d52-31a85eb7fe6f)

`kubectl describe node` 명령어의 출력 내용 중에서 'Non-terminated Pods' 항목에서 실행 중인 pods의 자원 할당량 확인 가능  
'Allocated resources' 항목에서는 해당 node에서 실행 중인 pods의 자원 할당량을 모두 더한 값이 표시

<br>

### Container와 pod의 자원 사용량 제한 - Request
적어도 이 만큼의 자원은 container에게 보장돼야 한다는 것을 의미

Node의 총 자원의 크기보다 더 많은 양의 requests 할당 불가  
K8s의 scheduler는 pod의 requests만큼 여유가 있는 node를 선택해 pod를 생성  
즉, pod를 할당할 때 사용되는 자원할당 기준은 limits가 아닌 requests

> **Note**  
> node에 할당된 pod의 limits 값의 합은 node의 물리 자원의 크기 초과 가능

<br>

#### Overcommit
Requests는 K8s에서 자원의 overcommit을 가능하게 만드는 기능

한정된 computing 자원을 효율적으로 사용하기 위한 방법  
사용 가능한 자원보다 더 많은 양을 가상 machine이나 container에게 할당함으로써 전체 자원의 사용률을 높이는 방법

<br>

#### Pod에 자원 사용량을 명시적으로 설정
`resource-limit-with-request-pod.yaml`
```yaml
apiVersion: v1
kind: pod
metadata:
  name: resource-limit-with-request-pod
  lables:
    name: resource-limit-with-request-pod
spec:
  containers:
  - name: nginx
    image: nginx:latest
  resources:
    limits:
      memory: "256Mi"
      cpu: "1000m"
    requests:
      memory: "128Mi"
      cpu: "500m"
```

<br>

### CPU 자원 사용량의 제한 원리
K8s는 CPU를 압축 가능한(compressible) resource라고 지칭  
Requests보다 더 많은 CPU를 사용해 CPU 경합이 발생하더라도 container의 CPU 사용량을 throttle을 통해 억제할 수 있기 때문

Memory나 storage는 압축 불가능(incompressible)한 resource라고 지칭  
Container간에 memory 사용의 경합이 발생하면 우선순위가 낮은 container의 process가 먼저 종료되기 때문

<br>

### QoS class와 memory 자원 사용량 제한 원리
Node에 memory 자원이 부족해지면 어떤 pod나 process가 먼저 종료돼야 하는지는 상당히 중요한 부분  
K8s는 pod의 container에 설정된 limits와 requests의 값에 따라 내부적으로 우선순위를 계산

<br>

#### K8s에서의 memory 부족과 OOM(Out Of Memory)
K8s의 node에는 각종 node의 이상 상태 정보를 의미하는 Conditions라는 값이 존재  
Kubelet은 node의 자원 상태를 주기적으로 확인하면서 Conditions의 MemoryPressure, DiskPressure 등의 값을 갱신

평소에 memory가 부족하지 않을 때는 MemoryPressure의 값이 False로 되어 있으나 memory가 부족해지면 MemoryPressure의 값이 True로 변경

MemoryPressure는 기본적으로 node의 가용 memory가 100Mi 이하일 때 발생하도록 kubelet에 설정된 상태  
MemoryPressure가 발생하면 K8s는 해당 node에서 실행 중이던 모든 pod에 대해 순위를 매긴 후, 가장 우선순위가 낮은 pod를 다른 node로 퇴거(Evict).
그리고 MemoryPressure의 값이 True인 node에는 더 이상 pod를 할당하지 않음

> **Note**  
> **Hard Eviction Threshold**
>
> MemoryPressure와 같이 상태를 감지하기 위한 임계치를 Hard Eviction Threshold라고 지칭  
> kubelet의 실행 옵션에서 설정값 변경 가능  
> Hard Eviction Threshold의 다른 예시로 DiskPressure가 있으며, DiskPressure의 상태가 활성화되면 K8s는 사용 중이지 않은 docker image를 자동으로 삭제

Kubelet이 MemoryPressure 상태를 감지하기 전에 급작스럽게 memory 사용량이 많아질 경우,
linux system의 OOM Killer가 우선순위 점수가 낮은 container의 process를 강제로 종료해 사용 가능한 memory를 확보

OOM Killer는 linux에 기본적으로 내장된 기능이므로 아무것도 설정하지 않아도 모든 process에 자동으로 OOM 점수가 매겨짐  
OOM 점수가 높으면 높을수록 강제로 종료될 가능성이 커지므로 절대로 종료되지 말아야 하는 핵심 process는 일반적으로 매우 낮은 값을 부여받음

process가 memory를 얼마나 더 많이 사용하고 있는지에 따라 process의 최종 OOM 점수(oom_ score)가 갱신되는데,
OOM Killer는 이 점수를 기준으로 최종적으로 종료할 process를 선정

<br>

#### QoS class의 종류 - Guaranteed class
K8s에서는 pod의 limits와 requests 값에 따라서 QoS class를 모든 pods에 대해서 설정

Guaranteed class는 pod의 container에 설정된 limits와 requests의 값이 완전히 동일할 때 부여되는 class  
Requests 없이 limits만 정의하면 requests의 값 또한 limits로 동일하게 설정  
즉, 자원의 overcommit이 허용되지 않으므로 할당받은 자원의 사용을 안정적으로 보장 가능

> **Note**  
> Pod 내의 container가 여러 개 존재한다면 모든 containers의 requests와 limits의 값이 완전히 같아야만 pod가 Guaranteed class로 분류

<br>

#### QoS class의 종류 - BestEffort class
Requests와 limits를 설정하지 않은 pod에 설정되는 class

Limits 값을 설정하지 않았으므로 node에 유휴 자원이 있다면 제한없이 모든 자원 사용 가능  
Requests 또한 설정하지 않아서 보장받을 수 있는 자원이 존재하지 않음

<br>

#### QoS class의 종류 - Burstable class
Requests와 limits가 설정돼 있지만, limits 값이 requests보다 큰 pod를 의미

Requests에 지정된 자원만큼 사용을 보장받을 수 있지만，상황에 따라서는 limits까지 자원 사용 가능  
Requests를 넘어 limits 범위 내에서 자원을 사용하려고 시도한다면 다른 pod와 자원 경합이 발생할 가능성 존재

<br>

#### QoS class와 memory 부족
Pod가 다른 node로 evict되면 단순히 다른 node에서 pod가 다시 생성될 뿐이지만, OOM Killer에 의해 pod container의 process가 종료되면 해당 container는 pod의 restartPolicy에 의해 다시 시작됨

> **Note**  
> OOM Killer는 memory를 많이 사용하고 있는 process를 강제로 종료하는 것이지, container나 pod를 종료시키는 것은 아님  
> Container 내부의 init process가 아닌 다른 process가 memory를 많이 사용하고 있다면 해당 process만 종료될 수 있음

기본적으로 pod의 우선순위는 Guaranteed - Burstable - BestEffort 순  
단, 이는 절대적인 것은 아니며 pod가 memory를 많이 사용할수록 우선순위가 낮아짐

<br>

### ResourceQuota와 LimitRange
특정 namespace에서 pod에 자원을 과도하게 사용해 버리면 다른 namespace에서는 자원이 부족한 상황 발생할 수도 있으니, 각 namespace에서 할당할 수 있는 자원의 최대 한도 또는 범위 설정 필요

<br>

#### ResourceQuota로 자원 사용량 제한
ResourceQuota는 특정 namespace에서 사용할 수 있는 자원 사용량의 합을 제한할 수 있는 K8s object
- Namespace에서 할당 가능한 자원의 총합 제한 가능
- Namespace에서 생성 가능한 resource의 개수 제한 가능

ResourceQuota는 namespace에 종속되는 object이므로 namespace별로 생성

`resource-quota.yaml`
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: resource-quota-example
  namespace: default
spec:
  hard:
    requests.cpu: "1000m"
    requests.memory: "500Mi"
    limits.cpu: "1500m"
    limits.memory: "1000Mi"
```

새롭게 생성되는 pod가 한계치보다 더 많은 자원을 사용하려고 하면 pod를 생성하는 API 요청은 실패  
단, ResourceQuota를 생성하기 이전에 존재하고 있던 pods가 이미 자원을 한계치보다 많이 사용하고 있다 해서 기존의 pod가 종료되진 않음

ResourceQuota는 다음과 같은 K8s object의 개수 제한 가능
- Deployment, Pod, Service, ConfigMap, PVC 등의 개수
- NodePort type의 service 개수, LoadBalancer type의 service 개수
- QoS class 중에서 BestEffort class에 속하는 pod의 개수

`quota-limit-pod-svc.yaml`
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: resource-quota-example
  namespace: default
spec:
  hard:
    requests.cpu: "1000m"
    requests.memory: "500Mi"
    limits.cpu: "1500m"
    limits.memory: "1000Mi"
    count/pods: 3
    count/services: 5
```

Resource의 개수를 제한할 때, 정의되는 K8s object 이름은 count/<object 이름>.<API group 이름>  
```yaml
...
spec:
  hard:
    count/resourcequotas: 3
    count/secrets: 3
    count/configmaps: 5
    count/persistentvolumeclaims: 2
    count/services.nodeports: 3
    count/services.loadbalancers: 1
    count/deployments.apps: 0
```

ResourceQuota를 사용하면 BestEffort class의 pod 개수 제한도 가능
`quota-limit-besteffort.yaml`
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: besteffort-quota
  namespace: default
spec:
  hard:
    count/pods: 1
  scopes:
    - BestEffort
```

scopes는 필수 항목은 아니지만, BestEffort 및 Terminating, NotTerminating, NotBestEffort와 같은 pod의 상태를 값으로 입력 가능

BestEffort class의 pod는 아무런 자원 할당을 설정하지 않은 경우에 해당하므로 hard 항목에서 limit.cpu나 limit.memory와 같은 자원 제한 설정과 연결되어 사용하지 않음.
BestEffort class의 pod 개수를 제한할 때는 count/pods만 유효하게 작동

> **Note**  
> Scopes에서 Terminating은 pod의 종료 시간(activeDeadlineSeconds)이 명시적으로 설정된 경우를 의미하는데 보통 job에서 사용

<br>

#### LimitRange로 자원 사용량 제한
특정 namespace에서 할당되는 자원의 범위 또는 기본값을 지정할 수 있는 K8s object
- Pod의 container에 CPU나 memory 할당량이 설정돼 있지 않은 경우, container에 자동으로 기본 requests 또는 limits 값 설정 가능
- Pod 또는 container의 CPU, memory, PVC storage 크기의 최솟값/최댓값 설정 가능

`limitrange-example.yaml`
```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: mem-limit-range
spec:
  limits:
  - default:
      memory: 256Mi
      cpu: 200m
    defaultRequest:
      memory: 128Mi
      cpu: 100m
    max:
      memory: 1Gi
      cpu: 1000m
    min:
      memory: 16Mi
      cpu: 50m
    type: Container
```

- **default**: pod의 container에 limits 값이 설정돼 있지 않다면 자동으로 이 값을 limits로 설정
- **defaultRequest**: pod의 container에 requests 값이 설정돼 있지 않다면 자동으로 이 값을 requests로 설정
- **max**: pod의 container에 설정될 수 있는 limits 값의 최대치
- **min**: pod의 container에 설정될 수 있는 requests 값의 최소치
- **type**: 이러한 자원 할당에 대한 설정이 어떤 단위로 적용될 것인지 명시. container, pod, PVC 입력 가능

LimitRange에서 maxLimitRequestRatio 항목을 사용하면 pod의 container에서 overcommit되는 자원에 대한 비율 제한 가능

`limitrange-ratio.yaml`
```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: limitrange-ratio
spec:
  limits:
  - maxLimitRequestRatio:
      memory: 1.5
      cpu: 1
    type: Container
```

Memory 기준으로 limits 값 / requests 값이 1.5가 넘는 pod의 container를 생성하려고 하면 오류 발생  
maxLimitRequestRatio는 overcommit을 얼마나 허용할 수 있는지 제어할 수 있을 뿐만 아니라, 이 값을 1로 설정함으로써 Guaranteed class의 pod만을 생성하도록 강제하는 용도로도 사용 가능

<br>

### ResourceQuota, LimitRange의 원리 - Admission Controller
Admission Controller는 사용자의 API 요청이 적절한지 검증(Validating)하고, 필요에 따라 API 요청을 변형(Mutating)하는 역할을 수행

<br>

#### 사용자의 요청이 최종적으로 처리되기까지의 단계
![image](https://github.com/bigmtn1113/K8s-Note/assets/46125158/09e911c9-8a12-4066-af2e-bb2bdfc5e124)

<br>

#### Admission Controller의 종류인 ResourceQuota와 LimitRange가 동작하는 방식
1. 사용자가 `kubectl apply -f pod.yaml` 같은 명령어로 API 서버에 요청 전송
2. x509 인증서, Service Account 등을 통해 인증
3. Role, Cluster Role 등을 통해 인가
4. 해당 API 요청에 포함된 pod data에 자원 할당이 설정되지 않은 경우, LimitRange는 pod data에 CPU 및 memory 할당의 기본값을 추가함으로써 원래의 pod 생성 API의 data 변형 수행
5. ResourceQuota는 해당 pod의 자원 할당 요청이 적절한지 검증. 부적절 시 API 요청 거절

필요하다면 Admission Controller를 직접 구현해 K8s에 등록하는 것 또한 가능

<br>

## Kubernetes scheduling
Scheduling이란 container나 가상 machine과 같은 instance를 새롭게 생성할 때, 그 instance를 어느 server에 생성할 것인지 결정하는 일

<br>

### Pod가 실제로 node에 생성되기까지의 과정
kube-scheduler는 K8s scheduler에 해당하며, etcd는 K8s cluster의 전반적인 상태 data를 저장하는 일종의 database 역할을 담당  
kube-scheduler와 etcd 또한 pod로써 실행되므로 `kubectl get pods -n kube-system` 명령어로 쉽게 확인 가능

![image](https://github.com/bigmtn1113/K8s-Note/assets/46125158/99ab558e-1fb5-4e32-aeda-042891d08caa)  
etcd에 저장된 data는 무조건 API 서버(kube-apiserver)를 통해서만 접근 가능

1. 인증, 인가, admission controller 등의 단계를 거쳐 pod 생성 요청이 최종적으로 승인됐다면 API 서버는 etcd에 pod의 data를 저장  
  하지만 API 서버는 pod의 data 중에서 nodeName을 설정하지 않은 상태로 etcd에 저장  
  Scheduling이 수행되지 않았기 때문
2. kube-scheduler는 API server의 Watch를 통해 nodeName이 비어 있는 pod data가 저장됐다는 사실을 전달 받음
3. kube-scheduler는 nodeName이 설정되지 않은 pod를 scheduling 대상으로 판단하고,  
  pod를 할당할 적절한 node를 선택한 다음 API server에게 해당 node와 pod를 binding할 것을 요청
4. Pod의 nodeName 값에 선택된 node의 이름이 설정됨
5. kubelet은 API 서버에 걸어 둔 Watch를 통해 pod의 data에서 nodeName이 설정됐다는 소식을 전달 받음
6. 해당 nodeName에 해당하는 node의 kubelet이 container runtime을 통해 pod를 생성

<br>

### Pod가 생성될 node를 선택하는 scheduling 과정
Scheduler는 크게 Filtering, Scoring 단계를 거쳐 최종적으로 node를 선택
- **Filtering**: Pod를 할당할 수 있는 node와 그렇지 않은 node를 분리해 걸러내는 단계. 선정된 node의 목록은 scoring 단계로 전달
- **Scoring**: K8s의 source code에 미리 정의된 algorithm이 가중치에 따라서 node의 점수를 계산. 점수가 가장 높은 node를 최종적으로 선택

<br>

### NodeSelector와 Node Affinity, Pod Affinity
#### nodeName과 nodeSelector를 사용한 scheduling 방법
특정 worker node에 pod를 할당하는 가장 확실한 방법은 pod의 YAML file에 nodeName을 직접 명시

`nodename-nginx.yaml`
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  nodeName: <node name>
  containers:
  - name: nginx
    image: nginx:latest
```

Node 이름을 고정으로 설정했으므로 다른 환경에서 이 YAML file을 보편적으로 사용하기 힘듦  
또한 node에 장애가 발생했을 때도 유연하게 대처 불가

Label을 이용하면 특정 label이 존재하는 node에만 pod 할당 가능

```bash
kubectl label nodes <node 1 name> mylabel/disk=ssd
kubectl label nodes <node 2 name> mylabel/disk=hdd
kubectl label nodes <node 3 name> mylabel/disk=hdd
```

`nodeselector-nginx.yaml`
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-nodeselector
spec:
  nodeSelector:
    mylabel/disk: hdd
  containers:
  - name: nginx
    image: nginx:latest
```

nodeSelector는 해당 label이 존재하는 node 중 하나를 선택하므로 node의 이름에 종속적이지 않게 YAML file 작성 가능

<br>

#### Node Affinity를 이용한 scheduling 방법
Node Affinity는 nodeSelector에서 좀 더 확장된 label 선택 기능을 제공  
반드시 충족해야 하는 조건(Hard)와 선호하는 조건(Soft)을 별도로 정의 가능
- requiredDuringSchedulingIgnoredDuringExecution
- preferredDuringSchedulingIgnoredDuringExecution

`nodeaffinity-required.yaml`
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-nodeaffinity-required
spec:
  affinity:
    nodeAffinity:
      requireDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: mylabel/disk
            operator: In
            values:
            - ssd
            - hdd
  containers:
  - name: nginx
    image: nginx:latest
```

Node에 설정된 label이 반드시 mylabel/disk=ssd 또는 mylabel/disk=hdd여야 pod가 해당 node에 할당된다는 의미

`nodeaffinity-preferred.yaml`
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-nodeaffinity-preferred
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 80
        preference:
          matchExpressions:
          - key: mylabel/disk
            operator: In
            values:
            - ssd
  containers:
  - name: nginx
    image: nginx:latest
```

Node에 설정된 label이 mylabel/disk=ssd가 아닌 node에도 pod가 할당될 수 있으나 가급적이면 해당 label을 가진 node를 선택하도록 설정  
weight 값은 1에서 100까지의 값 사용 가능  
이 가중치는 scoring 단계에서 적용

단, 이러한 scheduling 조건은 pod를 할당할 당시에만 유효  
Pod가 할당된 뒤에 node의 label이 변경되더라도 다른 node로 pod가 옮겨가는 eviction이 발생하진 않음  
IgnoredDuringExecution라는 이름에서 동작 원리 유추 가능

> **Note**  
> **RequiredDuringExecution**  
> Scheduling에 영향을 주는 node label이 pod가 실행된 뒤에 변경됐다면 pod가 다른 node로 옮겨가게 됨

<br>

#### Pod Affinity를 이용한 scheduling 방법
Node Affinity가 특정 조건을 만족하는 node를 선택하는 방법이라면, Pod Affinity는 특정 조건을 만족하는 pod와 함께 실행되도록 scheduling

`podaffinity-required.yaml`
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-podaffinity
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredExecution:
      - labelSelector:
          matchExpressions:
          - key: mylabel/database
            operator: In
            values:
            - mysql
        topologyKey: topoloty.kubernetes.io/zone
  containers:
  - name: nginx
    image: nginx:latest
```

mylabel/database=mysql label을 가지는 pod와 함께 위치하도록 scheduling 설정

topologyKey는 해당 label을 가지는 topology 범위의 node를 선택한다는 것을 의미  
조건을 만족하는 pod와 동일한 node에 할당될 수 있지만, 해당 node와 동일한 topology에 속하는 다른 node에 pod가 할당될 수 있음

대표적으로 응답 시간을 최대한 줄여야 하는 두 개의 pod를 동일한 AZ 또는 region의 node에 할당하는 경우에 사용 가능

반드시 조건을 만족하는 pod와 동일한 node에 띄우려면 hostname을 이용  
모든 node의 host 이름은 고유하므로 하나의 topoloty에 두 개 이상의 node가 존재 불가

`podaffinity-hostname-topology.yaml`
```yaml
...
          matchExpressions:
          - key: mylabel/database
            operator: In
            values:
            - mysql
        topologyKey: kubernetes.io/hostname
...
```

> **Note**  
> `kubernetes.io/hostname` label은 K8s를 설치하면 기본적으로 모든 node에 설정되는 label  
> 이 label의 값은 각 node의 host 이름으로 설정됨

<br>

#### Pod Anti-affinity를 이용한 scheduling 방법
Pod Affinity가 특정 pod와 동일한 topology에 존재하는 node를 선택한다면, Pod Anti-affinity는 특정 pod와 같은 topology의 node를 선택하지 않는 방법.
이 원리를 잘 이용하면 고가용성 보장을 위해 pod를 여러 AZ 또는 region에 멀리 퍼뜨리는 전략 수립 가능

`pod-antiaffinity-required.yaml`
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod-antiaffinity
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
        matchExpressions:
        - key: mylabel/database
          operator: In
          values:
          - mysql
        topologyKey: topoloty.kubernetes.io/zone
  containers:
  - name: nginx
    image: nginx:latest
```

mylabel/database=mysql label이 설정된 pod가 kubernetes.io/zone=ap-northeast-2a label을 갖는 node에서 실행 중이라면 ap-northeast-2a label이 설정되지 않은 다른 topology 또는 node에 pod가 scheduling됨

이러한 원리를 이용해 Deployment을 DaemonSet처럼 설정 가능

`deployment-exclusive.yaml`
```yaml
apiVersion: apps/v1
kind: Deployment
...
spec:
  ...
  template:
    metadata:
      name: deployment-nginx
      labels:
        app: deployment-nginx
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - deployment-nginx
            topologyKey: kubernetes.io/hostname
      containers:
      - name: deployment-nginx
        image: nginx:latest
```

<br>

### Taints와 Tolerations 사용하기
#### Taints와 Tolerations를 이용한 pod scheduling
Taints라는 이름이 의미하는 것처럼 특정 node에 얼룩을 지정함으로써 해당 node에 pod가 할당되는 것을 막는 기능  
하지만 해당 Taints에 대응하는 Tolerations를 pod에 설정하면 Taints가 설정된 node에도 pod 할당 가능

Taints는 label과 비슷하게 key=value 형태로 사용  
다른 점은 key=value 뒤에 effect를 추가로 명시한다는 것  
- **NoSchedule**: Pod를 scheduling하지 않음
- **NoExecute**: Pod의 실행 자체를 허용하지 않음
- **PreferNoSchedule**: 가능하면 scheduling하지 않음

```bash
kubectl taint node <node name> alicek106/my-taint=dirty:NoSchedule
```
`toleration-test.yaml`
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-toleration-test
spec:
  tolerations:
  - key: alicek106/my-taint
    operator: Equal
    value: dirty
    effect: NoSchedule
  containers:
  - name: nginx
    image: nginx:latest
```

> **Note**  
> alicek106/my-taint=dirty:NoSchedule이라는 Taint를 용인  
> 해당 Taint가 설정된 node에 반드시 pod를 할당한다는 의미는 아님

```bash
kubectl describe node <control plane node name>
```
Control plane node에는 node-role.kubernetes.io/control-plane:NoSchedule이라는 이름의 Taints가 자동으로 설정되어 있는 상태  
또한, Unschedulable의 값이 false로 설정돼 있는데, 이는 scheduling의 대상이 되는 node라는 것을 의미  
Worker node와 마찬가지로 pod가 할당될 수 있는 node지만, Taints가 설정돼 있어서 일반적인 pods가 할당되지 않았던 것

> **Note**  
> Taint는 기본적으로 key=value 형태를 가지지만, value 생략 가능  
> value 생략 시 ""(빈 문자열)의 값을 가지는 것으로 간주

Control plane node에 설정된 Taint 또한 Toleration을 이용해 용인 가능

`toleration-controlplane.yaml`
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-controlplane-toleration
spec:
  tolerations:
  - key: node-role.kubernetes.io/control-plane
    operation: Equal
    value: ""
    effect: NoSchedule
  nodeSelector:
    node-role.kubernetes.io/control-plane: ""
  containers:
  - name: nginx
    image: nginx:latest
```

Toleration에서 operator의 값은 Equal 외에서 Exists 사용 가능  
이런 경우에는 Taint에 대한 wildcard로서 작동

![image](https://github.com/bigmtn1113/K8s-Note/assets/46125158/0bd240c1-7b56-4c5d-9028-78d54e20f9a8)

<br>

#### NoExecute와 tolerationSeconds
NoSchedule은 node에 설정하더라도 기존에 실행 중이던 pod는 정상적으로 동작하는 반면 NoExecute는 해당 node에서 아예 pod를 실행할 수 없도록 설정. 단, pod가 deployment나 ReplicaSet 등과 같은 resource로부터 생성됐다면 NoExecute에 의해 pod가 종료됐더라도 pod는 다른 node로 옮겨가는, 이른바 eviction이 발생

Pod를 생성하면 K8s는 자동으로 NoExecute에 대한 Toleration을 추가
```bash
kubectl describe pod <pod name>
```

node.kubernetes.io/not-ready와 unreachable이라는 Taint에 대해 Toleration이 설정돼 있음을 확인 가능  
이는 node가 준비되지 않았거나 network 통신이 불가능한 상황일 때를 위한 Toleration  
K8s는 특정 문제가 발생한 node에 대해서는 자동으로 Taint를 추가  

node.kubernetes.io/not-ready:NoExecute for 300s란 Toleration은 node에 장애가 발생해 not-ready 상태의 Taint가 발생하더라도 300초 동안은 해당 Taint를 용인하겠다는 뜻. Node에 장애가 생겨도 해당 node에서 실행 중이던 pod가 즉시 다른 node로 옮겨가는 것은 아니며, 기본적으로는 300초 후에 옮겨가게 됨. 이러한 option을 tolerationSeconds라고 부르며, pod가 실행 중인 node에 Taint가 추가됐을 때 해당 Taint를 용인할 수 있는 최대 시간을 의미

<br>

### Cordon, Drain 및 PodDistributionBudget
#### cordon은 이용한 scheduling 비활성화
Taint와 Toleration을 이용하는 방법보다 좀 더 명시적인 방법  
`kubectl cordon <node name>` 명령어를 사용하면 해당 node에 더 이상 pod가 scheduling되지 않음

```bash
kubectl cordon <node name>
kubectl get nodes
```
STATUS 항목에 SchedulingDisabled가 추가된 것 확인 가능

```bash
kubectl describe node <cordoned node name>
```
node.kubernetes.io/unschedulable:NoSchedule라는 이름의 Taint가 추가됐을 뿐만 아니라 Unschedulable 항목 또한 true로 설정되어 있는 것 확인 가능. 
단, cordon 명령어는 NoExcute가 아닌 NoSchedule 효과가 있는 Taint를 node에 추가하므로 해당 node에서 실행 중인 pod가 종료되지 않음

<br>

#### drain 명령어로 node 비활성화
drain은 cordon처럼 해당 node에 scheduling을 금지한다는 것은 같지만, eviction을 수행한다는 것이 차이점  
kernel version upgrade, 유지 보수 등의 이유로 인해 잠시 node를 중지해야 할 때 유용하게 사용 가능

```bash
kubectl drain <node name>
kubectl get nodes
```
STATUS 항목에 SchedulingDisabled가 추가된 것 확인 가능

Pod가 scheduling 되지 않게 cordon은 설정됐지만, 해당 node에서 실행 중이던 daemonset pod가 존재한다면 error가 발생  
이를 무시하려면 `--ignore-daemonsets` option 사용

단일 pod가 node에 존재할 때도 drain 명령어는 실패  
단일 pod는 종료되더라도 다른 node로 옮겨가 다시 생성되지 않기 때문  
이를 무시하려면 `--force` option 사용

<br>

#### PodDisruptionBudget으로 pod 개수 유지
`kubectl drain` 명령어 등으로 인해 pod에 eviction이 발생할 때, 특정 개수 또는 비율만큼의 pod는 반드시 정상적인 상태를 유지하기 위해 사용

`simple-pdb-example.yaml`
```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: simple-pdb-example
spec:
  maxUnavailable: 1
  # minUnavailable: 2
  selector:
    matchLabels:
      app: webserver
```

maxUnavailable은 `kubectl drain` 등에 의해 node의 pod가 종료될 때, 최대 몇 개까지 동시에 종료될 수 있는지를 의미  
minUnavailable은 pod의 eviction이 발생할 때, 최소 몇 개의 pod가 정상 상태를 유지해야 하는지 의미  
단, 둘 중 하나만 정의 가능

selector에서는 PodDisruptionBudget이 적용될 pod의 label을 입력  
이때 deployment 같은 controller의 label이 아닌, pod의 label을 입력할 것

> **Note**  
> `kubectl delete pod` 명령어는 PodDisruptionBudeget과 상관 없이 pod를 삭제  
> Eviction은 K8s 내부에서 Evict라는 별도의 API로 구현돼 있어 PodDisruptionBudget의 영향을 받아 pod를 삭제

<br>

### Custom Scheduler
#### Custom Scheduler 구현
K8s는 `kube-system` namespace에 존재하는 `kube-scheduler` 외에도 여러 개의 scheduler를 동시에 사용할 수 있도록 지원  
이때 별도의 scheduler는 직접 구현하거나 설정 필요

Pod를 생성할 때 schedulerName 항목을 정의하지 않으면 K8s는 기본적으로 `defualt-scheduler`라는 값을 설정  
이는 기본 scheduler인 `kube-scheduler` pod를 의미

기본 scheduler가 아닌 custom scheduler로 pod를 scheduling하고 싶다면 pod 생성 시 schedulerName의 값을 별도로 명시

`custom-scheduled-pod.yaml`
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: custom-scheduled-pod
spec:
  schedulerName: my-custom-scheduler
  containers:
  - name: nginx
    image: nginx:latest
```

이후 pod를 scheduling할 수 있는 custom scheduler를 K8s SDK를 이용해 직접 구현

<br>

## Kubernetes application 상태와 배포
K8s는 application을 안정적으로 배포할 수 있도록 몇 가지 기능을 제공

<br>

### Deployment를 통해 Rolling Update
#### Deployment를 이용한 ReplicaSet의 version 관리
Deployment에서 변경 사항이 생기면 새 ReplicaSet이 생성되고, 그에 따라 새 version의 application이 배포됨  
이때 `--record` option을 추가해 deployment의 변경 사항을 적용하면 이전에 사용하던 ReplicaSet의 정보는 deployment의 history에 기록됨

```bash
kubectl apply -f <deployment v1 file> --record
kubectl apply -f <deployment v2 file> --record

kubectl rollout history deployment <deployment name>
```

> **Note**  
> 기본적으로는 ReplicaSet의 revision은 10개까지만 history에 저장  
> Deployment를 생성할 때 `revisionHistoryLimit` 항목을 직접 설정함으로써 revision의 최대 개수 지정 가능
> ```yaml
> ...
> metadata:
>   name: deployment-history-limit
> spec:
>   revisionHistoryLimit: 3
> ...
> ```

<br>

#### Deployment를 통한 Rolling Update 설정
일시적으로 사용자의 요청을 처리하지 못해도 괜찮은 application이라면 ReCreate 방법 사용 가능  
기존 version의 pod를 모두 삭제한 뒤, 새로운 version의 pod를 생성하는 방식

`deployment-recreate-v1.yaml`
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-recreate
spec:
  replicas: 3
  strategy:
    type: Recreate
...
```

```bash
kubectl apply -f <deployment v1 file> --record
kubectl apply -f <deployment v2 file> --record

kubectl get pods
```

Application의 중단이 허용되지 않을 경우에 대비해 K8s는 pod를 조금씩 삭제하고 생성하는 Rolling Update 기능을 제공  
Deployment의 version을 update할 때는 기본적으로 Rolling Update를 사용하도록 설정돼 있으나 세부 항목 설정 가능

`deployment-rolling-update.yaml`
```yaml
...
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 2
      maxUnavailable: 2
...
```

- `maxUnavailable`: Rolling Update 도중 사용 불가능한 상태가 되는 pod의 최대 개수 설정. 실행 중인 pod의 개수가 일정 값 이하로 내려가지 않도록 유지
- `maxSurge`: Rolling Update 도중 전체 pod의 개수가 deployment의 replicas 값보다 얼마나 더 많이 존재할 수 있는지 설정. 새로운 version의 pod가 얼마나 많이 생성될 수 있는지를 의미

Option의 값은 숫자나 비율을 값으로 사용가능하며, 비율을 사용할 때 `maxSurge`의 소수점 값은 반올림되고 `maxUnavailable`의 소수점 값은 버려짐. 또한, 두 option 모두 기본값은 25%

> **Note**  
> Rolling Update를 사용하면 특정 순간에는 기존 version과 새 version의 application이 공존할 가능성 존재
> Application과 통신하는 다른 components는 어떠한 version과 통신해도 전체 system에 문제가 발생하지 않아야 함

<br>

#### Blue/Green 배포 사용
기존 version의 pod를 그대로 놔둔 상태에서 새로운 version의 pod를 미리 생성해 둔 뒤 service의 routing만 변경하는 배포 방식

해당 기능은 K8s에서 자체적으로 지원하는 것은 아니지만, 구현 가능  
![image](https://github.com/bigmtn1113/K8s-Note/assets/46125158/f7e51f5d-1046-4eec-b5c1-bb8eb4a6e022)

1. 기존 version(v1)의 deployment가 생성돼 있으며, service는 사용자 요청을 v1 pod로 전달 중
2. 새 version(v2)의 deployment 생성
3. Service의 label을 변경함으로써 service를 통한 요청이 v2의 deployment로 전달되도록 수정
4. v2의 deployment가 잘 작동하면 v1의 deployment 삭제. Roll Back이 필요할 시 service의 label을 되돌림

Rolling Update와 달리 특정 순간에 두 version의 application이 공존하지 않으며, ReCreate 전략처럼 중단 시간이 발생하지 않는다는 장점이 있으나, 특정 순간에는 deployment에 설정된 replicas 개수의 두 배에 해당하는 pod가 실행되므로 일시적으로 전체 자원을 많이 소모할 가능성 존재

<br>

### Pod의 Lifecycle
#### Pod의 상태와 Lifecycle
Pod의 상태 종류
- **Pending**: Pod를 생성하는 요청이 API server에 의해 승인됐지만, 아직 실제로 생성되지 않은 상태. node에 scheduling 되지 않았을 때도 pending.
- **Running**: Pod에 포함된 containers가 모두 생성돼 pod가 정상적으로 실행된 상태
- **Completed**: Pod가 정상적으로 실행돼 종료됐음을 의미. pod container의 init process가 종료 code로서 0을 반환한 경우
- **Error**: Pod가 정상적으로 실행되지 않은 상태로 종료됐음을 의미. pod container의 init process가 종료 code로서 0이 아닌 값을 반환한 경우
- **Terminating**: Pod가 삭제 또는 퇴거되기 위해 삭제 상태에 머물러 있는 경우

> **Note**  
> init process는 linux system이 구동될 때 가장 먼저 실행되는 process로, 일반적으로 PID가 1인 process를 의미  
> init process가 종료되면 container 또한 종료됨

`completed-pod.yaml`
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: completed-pod-example
spec:
  containers:
  - name: completed-pod-example
    image: busybox
    command: ["sh"]
    args: ["-c", "sleep 10 & exit 0"]
```

해당 예제로 pod를 생성하면 처음엔 Running 상태가 되고, 나중엔 Completed 상태로 전환되나 계속해서 다시 실행됨과 동시에 RESTARTS 횟수 또한 증가.
이는 기본적으로 pod의 재시작 정책을 설정하는 `restartPolocy` 속성이 Always로 설정돼 있기 때문.
`restartPolicy`를 Always로 설정하면 pod의 container가 종료됏을 때 자동으로 다시 재시작됨

`restartPolicy`를 Never로 설정하면 pod가 종료되어도 다시 시작하지 않지만, OnFailure로 설정하면 pod의 container가 0이 아닌 종료 code를 반환했을 때만 pod를 재시작

`completed-pod-restart-never.yaml`
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: completed-pod-restart-never
spec:
  restartPolicy: Never
  containers:
...
```

```bash
kubectl get pods --watch
```
Pod가 종료된 뒤에도 다시 재시작하지 않고 계속해서 Completed 상태에 머물러 있는 것 확인 가능  
종료 code가 1이 반환됐으면 pod가 Error 상태로 표시됨

`restartPolicy`에 따른 pod의 container 상태 변화  
![image](https://github.com/bigmtn1113/K8s-Note/assets/46125158/a7026e91-e660-4b71-8f5c-1c0cca96df74)

K8s에서는 어떠한 작업이 실패했을 때, 일정 간격을 두고 해당 작업을 다시 시도  
실패하는 횟수가 늘어날수록 재시도하는 간격이 지수 형태로 늘어나게 되는데, 그 중간 상태가 CrashLoopBackOff

<br>

#### Running 상태가 되기 위한 조건
Pod를 생성했다고 해서 무조건 Running 상태가 되는 것은 아니고, pod가 Running 상태에 머물러 있다고 해서 container 내부의 application이 제대로 작동하고 있을 것이라는 보장은 없음.
이를 위해 K8s는 다음과 같은 기능 제공
- `Init Container`
- `postStart`
- `livenessProbe`, `readinessProbe`

`Init Container`는 pod의 container 내부에서 application이 실행되기 전에 초기화를 수행하는 container  
1개 이상의 `Init Container`를 정의한 경우, 각 `Init Container`가 순서대로 실행됨

`init-container-example.yaml`
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: init-container-example
spec:
  initContainers:
  - name: my-init-container
    image: busybox
    command: ["sh", "-c", "echo Hello World!"]
  containers:
  - name: nginx
    image: nginx
```

Pod 상태 변화를 보면 처음에 상태가 `Init:0/1`로 표시되는 것 확인 가능  
`Init Container`가 하나라도 실패하게 된다면 pod의 application container는 실행되지 않으며, pod의 `restartPolicy`에 따라 `Init Container`가 재시작됨

Pod의 container가 시작될 때 실행되는 `postStart`은 두 가지 방식으로 사용 가능
- **HTTP**: Container가 시작한 직후, 특정 주소로 HTTP 요청을 전송
- **Exec**: Container가 시작한 직후, container 내부에서 특정 명령어를 실행

`poststart-hook.yaml`  
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: poststart-hook
spec:
  containers:
  - name: poststart-hook
    image: nginx
    lifecycle:
      postStart:
        exec:
          command: ["sh", "-c", "touch /myfile"]
```

단, `postStart`는 container의 Entrypoint와는 비동기적으로 실행되며, 어떠한 것이 먼저 실행된다는 보장은 없음

`postStart`의 명령어나 HTTP 요청이 제대로 실행되지 않으면 container는 Running 상태로 전환되지 않으며,  
`Init container`와 마찬가지로 `restartPolicy`에 의해 해당 container가 재시작됨

> **Note**  
> `Init Container`의 log는 `kubectl logs <pod name> -c <container name>`으로 확인 가능  
> 하지만 `postStart`에 의한 실행 log는 error가 발생하지 않는 한 별도로 확인 불가

